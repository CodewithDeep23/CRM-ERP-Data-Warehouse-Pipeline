{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f049c3-234a-438f-b614-bd02853eaa2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### BRONZE INGESTION PIPELINE  \n",
    "**RAW GCS â†’ BRONZE LAYER (DELTA TABLES)**\n",
    "\n",
    "---\n",
    "\n",
    "#### Purpose\n",
    "This notebook implements the **BRONZE layer ingestion** for the Data Lakehouse.\n",
    "\n",
    "It reads raw data files (e.g., CSV) from **Google Cloud Storage (GCS)**, performs minimal parsing, and writes them in **Delta Lake** format to the **BRONZE layer** in the medallion architecture.\n",
    "\n",
    "---\n",
    "\n",
    "#### Actions Performed\n",
    "- Reads raw source data from GCS buckets (CRM and ERP systems)\n",
    "- Converts raw CSV data into Delta format\n",
    "- Saves curated raw copies in the BRONZE folder of the Data Lake\n",
    "- Records **audit logs** of ingestion (table name, record counts, status)\n",
    "\n",
    "---\n",
    "\n",
    "#### Characteristics of BRONZE Layer\n",
    "- Immutable historical raw ingested data\n",
    "- Schema inferred at load time\n",
    "- Minimal transformations (parsing only, no business logic)\n",
    "- Provides consistent, structured Delta tables for downstream **SILVER layer**\n",
    "\n",
    "---\n",
    "\n",
    "#### Audit / Lineage\n",
    "- Ingestion metadata is logged as a Delta table (`_bronze_audit_logs`)\n",
    "- Includes table name, source path, load timestamp, record counts, and status\n",
    "\n",
    "---\n",
    "\n",
    "#### Parameters\n",
    "- Paths to raw data sources (GCS)\n",
    "- Target BRONZE Delta location in GCS\n",
    "\n",
    "---\n",
    "\n",
    "#### Usage Notes\n",
    "- Designed to be **idempotent** (overwrite mode for each Delta table)\n",
    "- Configurable list of source files in notebook (easy to add/remove sources)\n",
    "- Intended for **regular batch schedule** or **triggered orchestration**\n",
    "\n",
    "---\n",
    "\n",
    "#### Example Usage\n",
    "- Databricks interactive notebook.\n",
    "- Databricks job scheduled for nightly ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f5e1c75-f082-432c-b149-7e7acd69903c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, TimestampType\n",
    "from pyspark.sql.functions import to_date, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b516b0cb-4768-4ac7-9770-19102242059a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "datalake_crm_path = 'gs://my-bucket-deep/Data-Lake/source_crm/'\n",
    "datalake_erp_path = 'gs://my-bucket-deep/Data-Lake/source_erp/'\n",
    "\n",
    "# Bronze layer path\n",
    "bronze_path = 'gs://my-bucket-deep/Medallion/bronze'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ecb9eff-3000-4a0e-99cb-e877c11f40bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Config Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f492dc-a918-4eb3-a755-f023e219052c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration: list of data sources\n",
    "\n",
    "bronze_sources = [\n",
    "    {\n",
    "        \"name\": \"crm_cust_info\",\n",
    "        \"path\": f\"{datalake_crm_path}cust_info.csv\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\": {\"header\": True, \"inferSchema\": True}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"crm_prd_info\",\n",
    "        \"path\": f\"{datalake_crm_path}prd_info.csv\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\": {\"header\": True, \"inferSchema\": True}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"crm_sales_details\",\n",
    "        \"path\": f\"{datalake_crm_path}sales_details.csv\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\": {\"header\": True, \"inferSchema\": True}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"erp_cust_az12\",\n",
    "        \"path\": f\"{datalake_erp_path}CUST_AZ12.csv\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\": {\"header\": True, \"inferSchema\": True}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"erp_loc_a101\",\n",
    "        \"path\": f\"{datalake_erp_path}LOC_A101.csv\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\": {\"header\": True, \"inferSchema\": True}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"erp_px_cat_g1v2\",\n",
    "        \"path\": f\"{datalake_erp_path}PX_CAT_G1V2.csv\",\n",
    "        \"format\": \"csv\",\n",
    "        \"options\": {\"header\": True, \"inferSchema\": True}\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6238c3c2-53d4-46df-a8e1-69fec04e0c8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Expected Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea154de0-83d8-4072-b1fb-8caa5443d169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_df = spark.read.json('gs://my-bucket-deep/Data-Lake/config/expected_schemas.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43efe17c-6bf3-4293-9930-70ed37b16091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We need a Python dictionary, not a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bcf4f6b-f310-4d09-92e2-511039fc0a6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Expected schema config\n",
    "from google.cloud import storage\n",
    "import json\n",
    "\n",
    "# config in GCS\n",
    "bucket_name = \"my-bucket-deep\"\n",
    "blob_path = \"Data-Lake/config/expected_schemas.json\"\n",
    "\n",
    "# Initialize client\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(bucket_name)\n",
    "blob = bucket.blob(blob_path)\n",
    "\n",
    "# Download as string\n",
    "content = blob.download_as_text()\n",
    "\n",
    "# Parse JSON\n",
    "expected_schemas_raw = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "954cebdc-fec0-40f3-9496-7aba718c1856",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_schemas loaded: ['crm_cust_info', 'crm_prd_info', 'crm_sales_details', 'erp_loc_a101', 'erp_cust_az12', 'erp_px_cat_g1v2']\n"
     ]
    }
   ],
   "source": [
    "type_map = {\n",
    "    \"StringType\": StringType(),\n",
    "    \"IntegerType\": IntegerType(),\n",
    "    \"DateType\": DateType(),\n",
    "    \"TimestampType\": TimestampType()\n",
    "}\n",
    "\n",
    "expected_schemas = {}\n",
    "\n",
    "for table, fields in expected_schemas_raw.items():\n",
    "    struct_fields = [StructField(f['name'], type_map[f['type']], True) for f in fields]\n",
    "    expected_schemas[table] = StructType(struct_fields)\n",
    "\n",
    "print(\"expected_schemas loaded:\", list(expected_schemas.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d6fc5a8-f5e1-4bab-8e9f-6fbcf2cad9b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Logging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29982852-86d1-4771-a710-0c5024799898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Utility Logger\n",
    "def log(msg):\n",
    "    print(f\"[{datetime.now().isoformat()}] {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ee26b9a-4feb-41b2-8157-b8b59a624146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Type Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f66cbccd-fd52-4539-a35b-d60149a0d513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def cast_columns(df, expected_schema):\n",
    "    for field in expected_schema.fields:\n",
    "        col_name = field.name\n",
    "        if col_name in df.columns:\n",
    "            if isinstance(field.dataType, DateType):\n",
    "                df = df.withColumn(col_name, to_date(col_name))\n",
    "            elif isinstance(field.dataType, TimestampType):\n",
    "                df = df.withColumn(col_name, to_timestamp(col_name))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fee1abdd-feef-4279-a5f7-d10d888b6631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Schema validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea02f761-7027-4659-af71-56a89a647ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def normalize_type(t):\n",
    "    if t in (\"date\", \"timestamp\"):\n",
    "        return \"timestamp\"\n",
    "    return t\n",
    "\n",
    "def validate_schema(df, expected_schema, table_name):\n",
    "    actual_fields = set((f.name, normalize_type(f.dataType.simpleString())) for f in df.schema.fields)\n",
    "    expected_fields = set((f.name, normalize_type(f.dataType.simpleString())) for f in expected_schema.fields)\n",
    "\n",
    "    if actual_fields != expected_fields:\n",
    "        raise Exception(\n",
    "            f\"Schema mismatch for {table_name}.\\nExpected: {expected_fields}\\nActual: {actual_fields}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "243248a9-f690-487f-b588-12247a7dff12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Bronze Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee55eca2-64c0-4703-b066-1a9fd6da9355",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_to_bronze_table(source, bronze_base_path):\n",
    "    try:\n",
    "        log(f\"START: Loading {source['name']} from {source['path']}\")\n",
    "\n",
    "        df = spark.read.format(source['format']).options(**source['options']).load(source['path'])\n",
    "\n",
    "        df = df.toDF(*[c.lower() for c in df.columns])\n",
    "\n",
    "        df = cast_columns(df, expected_schemas[source['name']])\n",
    "\n",
    "        # Schema Validation (if defined)\n",
    "        if source['name'] in expected_schemas:\n",
    "            validate_schema(df, expected_schemas[source['name']], source['name'])\n",
    "            log(f\"INFO: Schema validation passed for {source['name']}\")\n",
    "\n",
    "        # Basic check\n",
    "        record_count = df.count()\n",
    "        log(f\"INFO: {source['name']} loaded with {record_count} records\")\n",
    "\n",
    "        # Write as Delta\n",
    "        output_path = f\"{bronze_base_path}/{source['name']}\"\n",
    "        df.write.format('delta').mode('overwrite').option('overwriteSchema', 'true').save(output_path)\n",
    "\n",
    "        log(f\"SUCCESS: Written {source['name']} to {output_path}\")\n",
    "\n",
    "        return {\n",
    "            \"table_name\": source['name'],\n",
    "            \"status\": \"SUCCESS\",\n",
    "            \"records\": record_count,\n",
    "            \"error\": None,\n",
    "            \"loaded_at\": datetime.now().isoformat(),\n",
    "            \"source_path\": source['path']\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"ERROR: Failed to load {source['name']} - {e}\")\n",
    "        return {\n",
    "            \"table_name\": source['name'],\n",
    "            \"status\": \"FAILED\",\n",
    "            \"records\": 0,\n",
    "            \"error\": str(e),\n",
    "            \"loaded_at\": datetime.now().isoformat(),\n",
    "            \"source_path\": source['path']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ee26c22-38f1-49b5-9900-395219633252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Audit Schema\n",
    "audit_schema = StructType([\n",
    "    StructField(\"table_name\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"records\", IntegerType(), True),\n",
    "    StructField(\"error\", StringType(), True),\n",
    "    StructField(\"loaded_at\", StringType(), True),\n",
    "    StructField(\"source_path\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fce4a521-8d0f-4e3d-a9de-e24ea12700eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-30T07:50:48.402201] START: Loading crm_cust_info from gs://my-bucket-deep/Data-Lake/source_crm/cust_info.csv\n[2025-06-30T07:50:54.579091] INFO: Schema validation passed for crm_cust_info\n[2025-06-30T07:50:57.431256] INFO: crm_cust_info loaded with 18494 records\n[2025-06-30T07:51:17.409793] SUCCESS: Written crm_cust_info to gs://my-bucket-deep/Medallion/bronze/crm_cust_info\n[2025-06-30T07:51:17.410014] START: Loading crm_prd_info from gs://my-bucket-deep/Data-Lake/source_crm/prd_info.csv\n[2025-06-30T07:51:20.595515] INFO: Schema validation passed for crm_prd_info\n[2025-06-30T07:51:21.107917] INFO: crm_prd_info loaded with 397 records\n[2025-06-30T07:51:30.482537] SUCCESS: Written crm_prd_info to gs://my-bucket-deep/Medallion/bronze/crm_prd_info\n[2025-06-30T07:51:30.482753] START: Loading crm_sales_details from gs://my-bucket-deep/Data-Lake/source_crm/sales_details.csv\n[2025-06-30T07:51:33.251175] INFO: Schema validation passed for crm_sales_details\n[2025-06-30T07:51:34.036008] INFO: crm_sales_details loaded with 60398 records\n[2025-06-30T07:51:41.693442] SUCCESS: Written crm_sales_details to gs://my-bucket-deep/Medallion/bronze/crm_sales_details\n[2025-06-30T07:51:41.693630] START: Loading erp_cust_az12 from gs://my-bucket-deep/Data-Lake/source_erp/CUST_AZ12.csv\n[2025-06-30T07:51:44.347245] INFO: Schema validation passed for erp_cust_az12\n[2025-06-30T07:51:44.950247] INFO: erp_cust_az12 loaded with 18484 records\n[2025-06-30T07:51:51.665503] SUCCESS: Written erp_cust_az12 to gs://my-bucket-deep/Medallion/bronze/erp_cust_az12\n[2025-06-30T07:51:51.665636] START: Loading erp_loc_a101 from gs://my-bucket-deep/Data-Lake/source_erp/LOC_A101.csv\n[2025-06-30T07:51:54.532131] INFO: Schema validation passed for erp_loc_a101\n[2025-06-30T07:51:55.132406] INFO: erp_loc_a101 loaded with 18484 records\n[2025-06-30T07:52:01.426354] SUCCESS: Written erp_loc_a101 to gs://my-bucket-deep/Medallion/bronze/erp_loc_a101\n[2025-06-30T07:52:01.426532] START: Loading erp_px_cat_g1v2 from gs://my-bucket-deep/Data-Lake/source_erp/PX_CAT_G1V2.csv\n[2025-06-30T07:52:02.849998] INFO: Schema validation passed for erp_px_cat_g1v2\n[2025-06-30T07:52:03.104877] INFO: erp_px_cat_g1v2 loaded with 37 records\n[2025-06-30T07:52:09.886245] SUCCESS: Written erp_px_cat_g1v2 to gs://my-bucket-deep/Medallion/bronze/erp_px_cat_g1v2\n"
     ]
    }
   ],
   "source": [
    "# Process all sources and collect audit records\n",
    "audit_records = []\n",
    "for source in bronze_sources:\n",
    "    result = load_to_bronze_table(source, bronze_path)\n",
    "    audit_records.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d173389-0f1f-479d-9651-8aa99ea0c154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-30T07:52:17.626211] SUCCESS: Audit logs written to gs://my-bucket-deep/Medallion/bronze/_bronze_audit_logs\n"
     ]
    }
   ],
   "source": [
    "# Write Audit Logs\n",
    "# Avoids ambiguous NoneType inference.\n",
    "# Clean records\n",
    "for rec in audit_records:\n",
    "    if rec[\"error\"] is None:\n",
    "        rec[\"error\"] = \"\"\n",
    "\n",
    "# Create DataFrame with explicit schema\n",
    "audit_df = spark.createDataFrame(audit_records, schema=audit_schema)\n",
    "\n",
    "# Write audit logs\n",
    "audit_log_path = f\"{bronze_path}/_bronze_audit_logs\"\n",
    "audit_df.write.format('delta').mode('append').save(audit_log_path)\n",
    "\n",
    "log(f\"SUCCESS: Audit logs written to {audit_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e722f82-1fea-4e1d-9dd1-67c6577f2c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>table_name</th><th>status</th><th>records</th><th>error</th><th>loaded_at</th><th>source_path</th></tr></thead><tbody><tr><td>crm_cust_info</td><td>SUCCESS</td><td>18494</td><td></td><td>2025-06-30T07:51:17.409965</td><td>gs://my-bucket-deep/Data-Lake/source_crm/cust_info.csv</td></tr><tr><td>crm_prd_info</td><td>SUCCESS</td><td>397</td><td></td><td>2025-06-30T07:51:30.482691</td><td>gs://my-bucket-deep/Data-Lake/source_crm/prd_info.csv</td></tr><tr><td>crm_sales_details</td><td>SUCCESS</td><td>60398</td><td></td><td>2025-06-30T07:51:41.693567</td><td>gs://my-bucket-deep/Data-Lake/source_crm/sales_details.csv</td></tr><tr><td>erp_cust_az12</td><td>SUCCESS</td><td>18484</td><td></td><td>2025-06-30T07:51:51.665599</td><td>gs://my-bucket-deep/Data-Lake/source_erp/CUST_AZ12.csv</td></tr><tr><td>erp_loc_a101</td><td>SUCCESS</td><td>18484</td><td></td><td>2025-06-30T07:52:01.426480</td><td>gs://my-bucket-deep/Data-Lake/source_erp/LOC_A101.csv</td></tr><tr><td>erp_px_cat_g1v2</td><td>SUCCESS</td><td>37</td><td></td><td>2025-06-30T07:52:09.886347</td><td>gs://my-bucket-deep/Data-Lake/source_erp/PX_CAT_G1V2.csv</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "crm_cust_info",
         "SUCCESS",
         18494,
         "",
         "2025-06-30T07:51:17.409965",
         "gs://my-bucket-deep/Data-Lake/source_crm/cust_info.csv"
        ],
        [
         "crm_prd_info",
         "SUCCESS",
         397,
         "",
         "2025-06-30T07:51:30.482691",
         "gs://my-bucket-deep/Data-Lake/source_crm/prd_info.csv"
        ],
        [
         "crm_sales_details",
         "SUCCESS",
         60398,
         "",
         "2025-06-30T07:51:41.693567",
         "gs://my-bucket-deep/Data-Lake/source_crm/sales_details.csv"
        ],
        [
         "erp_cust_az12",
         "SUCCESS",
         18484,
         "",
         "2025-06-30T07:51:51.665599",
         "gs://my-bucket-deep/Data-Lake/source_erp/CUST_AZ12.csv"
        ],
        [
         "erp_loc_a101",
         "SUCCESS",
         18484,
         "",
         "2025-06-30T07:52:01.426480",
         "gs://my-bucket-deep/Data-Lake/source_erp/LOC_A101.csv"
        ],
        [
         "erp_px_cat_g1v2",
         "SUCCESS",
         37,
         "",
         "2025-06-30T07:52:09.886347",
         "gs://my-bucket-deep/Data-Lake/source_erp/PX_CAT_G1V2.csv"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "table_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "records",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "error",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "loaded_at",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_path",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "audit_df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}